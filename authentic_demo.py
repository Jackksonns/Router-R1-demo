#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Router-R1 åŸºäºåŸé¡¹ç›®æ¶æ„çš„çœŸå®æ¼”ç¤º
ä½¿ç”¨åŸé¡¹ç›®çš„è·¯ç”±æœåŠ¡é€»è¾‘ï¼Œæ”¯æŒçœŸå®APIè°ƒç”¨æˆ–æ¨¡æ‹Ÿè°ƒç”¨
"""

import os
import re
import argparse
import time
from typing import Dict, Any

# å¯¼å…¥åŸé¡¹ç›®çš„æ ¸å¿ƒæ¨¡å—
from data_process import prompt_pool
from router_r1.llm_agent.route_service import (
    access_routing_pool,
    check_llm_name,
    AGENT_PROMPT,
    API_PRICE_1M_TOKENS
)

class RouterR1Demo:
    """
    åŸºäºåŸé¡¹ç›®æ¶æ„çš„ Router-R1 æ¼”ç¤ºç³»ç»Ÿ
    """
    
    def __init__(self, api_base: str = "mock://api", api_key: str = "demo-key", use_real_api: bool = False):
        self.api_base = api_base
        self.api_key = api_key
        self.use_real_api = use_real_api
        
        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.routing_history = []
        self.total_cost = 0.0
        self.turn_count = 0
        
    def get_query_from_text(self, text: str) -> str:
        """
        ä»æ–‡æœ¬ä¸­æå–<search>æŸ¥è¯¢ï¼Œä¸åŸé¡¹ç›®ä¿æŒä¸€è‡´
        """
        pattern = re.compile(r"<search>(.*?)</search>", re.DOTALL)
        matches = pattern.findall(text)
        return matches[-1].strip() if matches else None
    
    def mock_llm_response(self, model_name: str, query_text: str) -> tuple:
        """
        æ¨¡æ‹Ÿ LLM å“åº”
        """
        if "qwen" in model_name:
            response = f"æ ¹æ®æˆ‘çš„ä¸­è‹±æ–‡æ··åˆè®­ç»ƒï¼Œå¯¹äºæŸ¥è¯¢é—®é¢˜'{query_text}'ï¼Œæˆ‘å¯ä»¥æä¾›æŠ€æœ¯åˆ†æå’Œåº”ç”¨è§è§£ã€‚å¼ºåŒ–å­¦ä¹ åœ¨è¯­è¨€æ¨¡å‹ä¸­ä¸»è¦åº”ç”¨äºRLHFè®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒç­‰æ–¹é¢ã€‚"
        elif "llama" in model_name:
            if "70b" in model_name:
                response = f"Based on extensive training, I provide comprehensive analysis about '{query_text}'. Reinforcement learning applications include RLHF, PPO training, and reward model optimization."
            else:
                response = f"Regarding '{query_text}', reinforcement learning is used for human feedback alignment and instruction following."
        elif "mistral" in model_name:
            response = f"From European AI perspective on '{query_text}': RL techniques enable better human-AI alignment through feedback optimization."
        elif "gemma" in model_name:
            response = f"Google's research on '{query_text}': RL applications include constitutional AI and safety-oriented training methods."
        else:
            response = f"Analysis from {model_name} about '{query_text}': RL enhances model performance through iterative feedback."
        
        estimated_tokens = len(response.split()) + len(response) // 4
        return response, estimated_tokens
    
    def route_query_with_original_logic(self, query: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨åŸé¡¹ç›®çš„è·¯ç”±é€»è¾‘å¤„ç†æŸ¥è¯¢
        """
        print(f"ğŸ” è·¯ç”±æŸ¥è¯¢: {query}")
        
        if self.use_real_api:
            try:
                # ä½¿ç”¨åŸé¡¹ç›®çš„ access_routing_pool
                result = access_routing_pool(
                    queries=[query],
                    api_base=self.api_base,
                    api_key=self.api_key
                )
                response = result['result'][0]
                cost_list = result['completion_tokens_list']
                total_cost = sum(cost_list)
                model_name = "API_MODEL"
            except Exception as e:
                print(f"APIè°ƒç”¨å¤±è´¥: {e}")
                return {'success': False, 'error': str(e)}
        else:
            # æ¨¡æ‹Ÿè·¯ç”±è¿‡ç¨‹ï¼Œä½†ä½¿ç”¨åŸé¡¹ç›®çš„é€»è¾‘
            if ":" not in query:
                query = f"qwen2.5-7b-instruct:{query}"
            
            # ä½¿ç”¨åŸé¡¹ç›®çš„æ¨¡å‹åç§°æ˜ å°„
            target_llm = query.split(":")[0].strip().lower()
            query_text = query.split(":", 1)[1].strip()
            
            LLM_NAME, TAU = check_llm_name(target_llm=target_llm)
            
            if LLM_NAME == "":
                return {
                    'success': False,
                    'error': f"ä¸æ”¯æŒçš„æ¨¡å‹: {target_llm}",
                    'model_name': None,
                    'response': None,
                    'cost': 0.0
                }
            
            print(f"ğŸ¯ é€‰ä¸­æ¨¡å‹: {LLM_NAME} (TAU={TAU})")
            
            # ä½¿ç”¨åŸé¡¹ç›®çš„ AGENT_PROMPT æ¨¡æ¿
            input_prompt = AGENT_PROMPT.format_map({"query": query_text})
            
            # è°ƒç”¨æ¨¡æ‹Ÿçš„ LLM å“åº”
            response, completion_tokens = self.mock_llm_response(LLM_NAME, query_text)
            
            # ä½¿ç”¨åŸé¡¹ç›®çš„æˆæœ¬è®¡ç®—é€»è¾‘
            if LLM_NAME in API_PRICE_1M_TOKENS:
                total_cost = completion_tokens * API_PRICE_1M_TOKENS[LLM_NAME] / 1000000
            else:
                total_cost = completion_tokens * 0.0005 / 1000000
            
            model_name = LLM_NAME
        
        # è®°å½•è·¯ç”±å†å²
        routing_record = {
            'turn': self.turn_count,
            'query': query,
            'model_name': model_name,
            'response_length': len(response),
            'cost': total_cost,
            'timestamp': time.time()
        }
        self.routing_history.append(routing_record)
        self.total_cost += total_cost
        
        print(f"ğŸ“¥ æ¨¡å‹å“åº” ({len(response)}å­—ç¬¦): {response[:100]}{'...' if len(response) > 100 else ''}")
        print(f"ğŸ’° æœ¬è½®æˆæœ¬: ${total_cost:.6f}")
        
        return {
            'success': True,
            'model_name': model_name,
            'response': response,
            'cost': total_cost
        }
    
    def run_multi_turn_reasoning(self, question: str, max_turns: int = 3) -> Dict[str, Any]:
        """
        è¿è¡Œå¤šè½®æ¨ç†ï¼Œä½¿ç”¨åŸé¡¹ç›®çš„æ•´ä½“æ¶æ„
        """
        print(f"ğŸš€ å¯åŠ¨ Router-R1 å¤šè½®æ¨ç†ç³»ç»Ÿ")
        print(f"ğŸ“ é—®é¢˜: {question}")
        print("=" * 80)
        
        # ä½¿ç”¨åŸé¡¹ç›®çš„æç¤ºè¯æ¨¡æ¿
        question = question.strip()
        if question[-1] != '?':
            question += '?'
            
        current_prompt = prompt_pool.PROMPT_TEMPLATE_QWEN.format_map({"question": question})
        print(f"ğŸ¤– åˆå§‹æç¤ºè¯é•¿åº¦: {len(current_prompt)} å­—ç¬¦")
        print(f"ğŸ”— API é…ç½®: {self.api_base} (çœŸå®è°ƒç”¨: {self.use_real_api})")
        
        for turn in range(max_turns):
            self.turn_count = turn + 1
            print(f"\nğŸ”„ === ç¬¬ {turn + 1} è½®æ¨ç† ===")
            
            # æ¨¡æ‹Ÿç”ŸæˆåŒ…å« <search> æ ‡ç­¾çš„è¾“å‡º
            if turn == 0:
                mock_generation = f"<think>å¯¹äºé—®é¢˜ã€{question}ã€ï¼Œæˆ‘éœ€è¦è°ƒç”¨ä¸“ä¸šæ¨¡å‹è·å–æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚</think>\n<search>Qwen2.5-7B-Instruct:{question}çš„æŠ€æœ¯ç»†èŠ‚å’Œå®ç°æ–¹æ¡ˆ</search>"
            elif turn == 1:
                mock_generation = f"<think>åŸºäºä¹‹å‰çš„ä¿¡æ¯ï¼Œæˆ‘éœ€è¦ä»ä¸åŒè§’åº¦æ¥éªŒè¯å’Œè¡¥å……ã€‚</think>\n<search>LLaMA-3.1-70B-Instruct:{question}çš„æ·±åº¦åˆ†æå’Œæœ€ä½³å®è·µ</search>"
            else:
                mock_generation = f"<think>ç°åœ¨æˆ‘éœ€è¦ç»¼åˆä¹‹å‰çš„ä¿¡æ¯æ¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚</think>\n<answer>åŸºäºå¤šä¸ªä¸“å®¶æ¨¡å‹çš„åä½œåˆ†æï¼Œå¯¹äºã€{question}ã€çš„ç»¼åˆç­”æ¡ˆå¦‚ä¸‹ï¼šé€šè¿‡ Router-R1 ç³»ç»Ÿçš„æ™ºèƒ½è·¯ç”±ï¼Œæˆ‘ä»¬æˆåŠŸè°ƒç”¨äº†å¤šä¸ªä¸“ä¸šæ¨¡å‹ï¼Œè·å¾—äº†å…¨é¢è€Œæ·±å…¥çš„åˆ†æç»“æœã€‚</answer>"
            
            print(f"ğŸ“¤ åŸºç¡€æ¨¡å‹è¾“å‡º:\n{mock_generation}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­”æ¡ˆ
            if "<answer>" in mock_generation:
                print(f"\nâœ… æ£€æµ‹åˆ°æœ€ç»ˆç­”æ¡ˆï¼Œæ¨ç†ç»“æŸ")
                break
            
            # æå–æŸ¥è¯¢å¹¶è¿›è¡Œè·¯ç”±
            query = self.get_query_from_text(mock_generation)
            if query:
                routing_result = self.route_query_with_original_logic(query)
                if not routing_result['success']:
                    print(f"âš ï¸  è·¯ç”±å¤±è´¥: {routing_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    break
            else:
                print("âš ï¸  æœªæ£€æµ‹åˆ°æœç´¢æŸ¥è¯¢")
        
        return {
            'total_turns': self.turn_count,
            'total_cost': self.total_cost,
            'routing_history': self.routing_history,
            'api_calls': len(self.routing_history)
        }

def demonstrate_original_architecture(question: str, use_real_api: bool = False):
    """
    æ¼”ç¤ºåŸé¡¹ç›®æ¶æ„çš„è·¯ç”±åŠŸèƒ½
    """
    demo = RouterR1Demo(
        api_base="https://api.openai.com/v1" if use_real_api else "mock://demo-api",
        api_key="your-api-key" if use_real_api else "demo-key",
        use_real_api=use_real_api
    )
    
    print("ğŸ† Router-R1 åŸé¡¹ç›®æ¶æ„æ¼”ç¤º")
    print("=" * 80)
    print("âœ¨ æœ¬æ¼”ç¤ºä½¿ç”¨åŸé¡¹ç›®çš„æ ¸å¿ƒæ¨¡å—:")
    print("   - access_routing_pool: è·¯ç”±æ± ç®¡ç†")
    print("   - check_llm_name: æ¨¡å‹åç§°æ˜ å°„")
    print("   - AGENT_PROMPT: å®˜æ–¹æç¤ºè¯æ¨¡æ¿")
    print("   - API_PRICE_1M_TOKENS: å®˜æ–¹æˆæœ¬è®¡ç®—")
    print(f"   - çœŸå®APIè°ƒç”¨: {'âœ… å¼€å¯' if use_real_api else 'âŒ æ¨¡æ‹Ÿæ¨¡å¼'}")
    print("\n" + "=" * 80)
    
    result = demo.run_multi_turn_reasoning(question)
    
    print("\n" + "=" * 80)
    print("ğŸ“ˆ æ¼”ç¤ºç»Ÿè®¡:")
    print(f"   ğŸ”„ æ€»è½®æ¬¡: {result['total_turns']}")
    print(f"   ğŸ’° æ€»æˆæœ¬: ${result['total_cost']:.6f}")
    print(f"   ğŸ“¡ APIè°ƒç”¨: {result['api_calls']}æ¬¡")
    
    print("\nğŸ“ è·¯ç”±å†³ç­–è¯¦æƒ…:")
    for i, record in enumerate(result['routing_history'], 1):
        print(f"   {i}. {record['model_name']} (æˆæœ¬: ${record['cost']:.6f})")
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼å±•ç¤ºäº†åŸºäºåŸé¡¹ç›®æ¶æ„çš„çœŸå®è·¯ç”±ç³»ç»Ÿã€‚")
    return result

def main():
    parser = argparse.ArgumentParser(description='Router-R1 åŸé¡¹ç›®æ¶æ„æ¼”ç¤º')
    parser.add_argument('--question', type=str, 
                       default="ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨", 
                       help='è¦å›ç­”çš„é—®é¢˜')
    parser.add_argument('--real-api', action='store_true',
                       help='ä½¿ç”¨çœŸå®APIè°ƒç”¨ï¼ˆéœ€è¦é…ç½®APIå¯†é’¥ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸ† Router-R1 åŸºäºåŸé¡¹ç›®æ¶æ„çš„æ¼”ç¤ºç³»ç»Ÿ")
    print("âœ¨ ä½¿ç”¨åŸé¡¹ç›®çš„æ ¸å¿ƒç»„ä»¶å’Œè·¯ç”±é€»è¾‘")
    
    if args.real_api:
        print("\nâš ï¸  çœŸå®APIæ¨¡å¼éœ€è¦é…ç½®æœ‰æ•ˆçš„APIå¯†é’¥å’ŒåŸºç¡€URL")
    
    demonstrate_original_architecture(args.question, args.real_api)

if __name__ == "__main__":
    main()
