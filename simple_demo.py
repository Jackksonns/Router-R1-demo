#!/usr/bin/env python3
"""
Router-R1 åŸºäºåŸé¡¹ç›®æ¶æ„çš„çœŸå®æ¼”ç¤º
ä½¿ç”¨åŸé¡¹ç›®çš„è·¯ç”±æœåŠ¡é€»è¾‘ï¼Œæ”¯æŒçœŸå®APIè°ƒç”¨æˆ–æ¨¡æ‹Ÿè°ƒç”¨
"""

import os
import re
import json
import argparse
import time
from typing import List, Dict, Any

# å¯¼å…¥åŸé¡¹ç›®çš„æ ¸å¿ƒæ¨¡å—
from data_process import prompt_pool
from router_r1.llm_agent.route_service import (
    access_routing_pool,
    get_llm_response_via_api,
    check_llm_name,
    AGENT_PROMPT,
    API_PRICE_1M_TOKENS
)

class MockAPIService:
    """æ¨¡æ‹Ÿ API æœåŠ¡ï¼Œä¿æŒä¸åŸé¡¹ç›®ç›¸åŒçš„æ¥å£æ ¼å¼"""
    
    def __init__(self, use_real_api: bool = False):
        self.use_real_api = use_real_api
        self.call_history = []
        
    def mock_llm_response(self, model_name: str, prompt: str) -> tuple[str, int]:
        """æ¨¡æ‹Ÿ LLM å“åº”ï¼Œè¿”å›æ ¼å¼ä¸åŸ API ä¸€è‡´"""
        # æ¨¡æ‹Ÿä¸åŒæ¨¡å‹çš„å“åº”é£æ ¼
        if "qwen" in model_name:
            response = f"æ ¹æ®æˆ‘çš„ä¸­è‹±æ–‡æ··åˆè®­ç»ƒï¼Œå¯¹äºæŸ¥è¯¢é—®é¢˜ï¼Œæˆ‘å¯ä»¥æä¾›æŠ€æœ¯åˆ†æå’Œåº”ç”¨è§è§£ã€‚"
        elif "llama" in model_name:
            if "70b" in model_name:
                response = "Based on extensive training, I provide comprehensive analysis with theoretical foundations and practical implications."
            else:
                response = "I can offer insights based on my training, covering core concepts and real-world applications."
        elif "mistral" in model_name:
            response = "From European AI perspective: careful analysis of technical feasibility and ethical considerations."
        elif "gemma" in model_name:
            response = "Google's research insights: utilizing cutting-edge ML techniques and scalable solutions."
        else:
            response = f"Analysis from {model_name}: providing specialized domain expertise."
        
        estimated_tokens = len(response.split()) + len(response) // 4
        
        self.call_history.append({
            'model': model_name,
            'response_length': len(response),
            'estimated_tokens': estimated_tokens,
            'timestamp': time.time()
        })
        
        return response, estimated_tokens

class RouterR1Demo:
    """åŸºäºåŸé¡¹ç›®æ¶æ„çš„ Router-R1 æ¼”ç¤ºç³»ç»Ÿ"""
    
    def __init__(self, api_base: str = "mock://api", api_key: str = "demo-key", use_real_api: bool = False):
        self.api_base = api_base
        self.api_key = api_key
        self.use_real_api = use_real_api
        self.mock_service = MockAPIService(use_real_api)
        
        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.routing_history = []
        self.total_cost = 0.0
        self.turn_count = 0
        
    def get_query_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–<search>æŸ¥è¯¢ï¼Œä¸åŸé¡¹ç›®ä¿æŒä¸€è‡´"""
        pattern = re.compile(r"<search>(.*?)</search>", re.DOTALL)
        matches = pattern.findall(text)
        return matches[-1].strip() if matches else None
    
    def extract_answer(self, text: str) -> str:
        """æå–<answer>æ ‡ç­¾å†…å®¹"""
        pattern = re.compile(r"<answer>(.*?)</answer>", re.DOTALL)
        matches = pattern.findall(text)
        return matches[-1].strip() if matches else None
    
    def route_query_with_original_logic(self, query: str) -> Dict[str, Any]:
        """ä½¿ç”¨åŸé¡¹ç›®çš„è·¯ç”±é€»è¾‘å¤„ç†æŸ¥è¯¢"""
        print(f"ğŸ” è·¯ç”±æŸ¥è¯¢: {query}")
        
        if self.use_real_api:
            # ä½¿ç”¨åŸé¡¹ç›®çš„ access_routing_pool
            result = access_routing_pool(
                queries=[query],
                api_base=self.api_base,
                api_key=self.api_key
            )
            response = result['result'][0]
            cost_list = result['completion_tokens_list']
            total_cost = sum(cost_list)
            model_name = "API_MODEL"
        else:
            # æ¨¡æ‹Ÿè·¯ç”±è¿‡ç¨‹ï¼Œä½†ä½¿ç”¨åŸé¡¹ç›®çš„é€»è½¡
            if ":" not in query:
                query = f"qwen2.5-7b-instruct:{query}"
            
            # ä½¿ç”¨åŸé¡¹ç›®çš„æ¨¡å‹åç§°æ˜ å°„
            target_llm = query.split(":")[0].strip().lower()
            query_text = query.split(":", 1)[1].strip()
            
            LLM_NAME, TAU = check_llm_name(target_llm=target_llm)
            
            if LLM_NAME == "":
                return {
                    'success': False,
                    'error': f"ä¸æ”¯æŒçš„æ¨¡å‹: {target_llm}",
                    'model_name': None,
                    'response': None,
                    'cost': 0.0
                }
            
            print(f"ğŸ¯ é€‰ä¸­æ¨¡å‹: {LLM_NAME} (TAU={TAU})")
            
            # ä½¿ç”¨åŸé¡¹ç›®çš„ AGENT_PROMPT æ¨¡æ¿
            input_prompt = AGENT_PROMPT.format_map({"query": query_text})
            
            # è°ƒç”¨æ¨¡æ‹Ÿçš„ LLM å“åº”
            response, completion_tokens = self.mock_service.mock_llm_response(LLM_NAME, input_prompt)
            
            # ä½¿ç”¨åŸé¡¹ç›®çš„æˆæœ¬è®¡ç®—é€»è¾‘
            if LLM_NAME in API_PRICE_1M_TOKENS:
                total_cost = completion_tokens * API_PRICE_1M_TOKENS[LLM_NAME] / 1000000
            else:
                total_cost = completion_tokens * 0.0005 / 1000000
            
            model_name = LLM_NAME
        
        # è®°å½•è·¯ç”±å†å²
        routing_record = {
            'turn': self.turn_count,
            'query': query,
            'model_name': model_name,
            'response_length': len(response),
            'cost': total_cost,
            'timestamp': time.time()
        }
        self.routing_history.append(routing_record)
        self.total_cost += total_cost
        
        print(f"ğŸ“¥ æ¨¡å‹å“åº” ({len(response)}å­—ç¬¦): {response[:100]}{'...' if len(response) > 100 else ''}")
        print(f"ğŸ’° æœ¬è½®æˆæœ¬: ${total_cost:.6f}")
        
        return {
            'success': True,
            'model_name': model_name,
            'response': response,
            'cost': total_cost
        }
        
    def _initialize_experts(self) -> List[LLMExpert]:
        """åˆå§‹åŒ–ä¸“å®¶LLMæ± """
        experts = [
            LLMExpert(
                name="Qwen2.5-7B-Instruct",
                expertise=["ä¸­æ–‡", "æ•°å­¦", "ç¼–ç¨‹", "æ¨ç†"],
                model_size="7B",
                strengths={"reasoning": 0.8, "coding": 0.7, "chinese": 0.9, "math": 0.8}
            ),
            LLMExpert(
                name="LLaMA-3.1-8B-Instruct",
                expertise=["dialogue", "reasoning", "general"],
                model_size="8B", 
                strengths={"reasoning": 0.7, "dialogue": 0.8, "general": 0.8}
            ),
            LLMExpert(
                name="LLaMA-3.1-70B-Instruct",
                expertise=["complex reasoning", "analysis", "research"],
                model_size="70B",
                strengths={"reasoning": 0.95, "analysis": 0.9, "research": 0.9}
            ),
            LLMExpert(
                name="Mistral-7B-Instruct",
                expertise=["instruction following", "creative"],
                model_size="7B",
                strengths={"creativity": 0.8, "instruction": 0.85}
            ),
            LLMExpert(
                name="Mixtral-8x22B-Instruct",
                expertise=["multilingual", "coding", "complex tasks"],
                model_size="22B",
                strengths={"multilingual": 0.9, "coding": 0.85, "complex": 0.9}
            ),
            LLMExpert(
                name="Gemma-2-27B-Instruct",
                expertise=["reasoning", "code generation", "QA"],
                model_size="27B",
                strengths={"reasoning": 0.85, "coding": 0.8, "qa": 0.9}
            )
        ]
        return experts
    
    def classify_query_type(self, query: str) -> str:
        """åˆ†ç±»æŸ¥è¯¢ç±»å‹"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ["ä»£ç ", "programming", "ç¼–ç¨‹", "code", "algorithm"]):
            return "coding"
        elif any(word in query_lower for word in ["åˆ†æ", "analysis", "ç ”ç©¶", "research"]):
            return "analysis" 
        elif any(word in query_lower for word in ["æ•°å­¦", "math", "è®¡ç®—", "calculate"]):
            return "math"
        elif any(word in query_lower for word in ["åˆ›æ„", "creative", "åˆ›ä½œ", "story"]):
            return "creativity"
        elif any(word in query_lower for word in ["æ¨ç†", "reasoning", "é€»è¾‘", "logic"]):
            return "reasoning"
        else:
            return "general"
    
    def route_query(self, query: str, cost_budget: float = 0.001) -> Tuple[LLMExpert, float, str]:
        """è·¯ç”±æŸ¥è¯¢åˆ°æœ€é€‚åˆçš„LLM"""
        query_type = self.classify_query_type(query)
        
        # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„é€‚åˆåº¦åˆ†æ•°
        candidates = []
        for expert in self.experts:
            suitability = expert.is_suitable_for(query, query_type)
            cost_efficiency = suitability / expert.cost_per_token  # æ€§ä»·æ¯”
            
            candidates.append({
                'expert': expert,
                'suitability': suitability,
                'cost_efficiency': cost_efficiency,
                'cost': expert.cost_per_token
            })
        
        # æ’åºï¼šä¼˜å…ˆè€ƒè™‘é€‚åˆåº¦ï¼Œå…¶æ¬¡è€ƒè™‘æ€§ä»·æ¯”
        candidates.sort(key=lambda x: (x['suitability'], x['cost_efficiency']), reverse=True)
        
        # é€‰æ‹©æœ€ä¼˜å€™é€‰è€…
        best_candidate = candidates[0]
        selected_expert = best_candidate['expert']
        confidence = best_candidate['suitability']
        
        # è®°å½•è·¯ç”±å†å²
        routing_decision = {
            'query': query,
            'query_type': query_type,
            'selected_expert': selected_expert.name,
            'confidence': confidence,
            'cost': selected_expert.cost_per_token,
            'reasoning': f"é€‰æ‹©{selected_expert.name}ï¼Œå› ä¸ºå…¶åœ¨{query_type}ä»»åŠ¡ä¸Šé€‚åˆåº¦ä¸º{confidence:.2f}"
        }
        self.routing_history.append(routing_decision)
        
        return selected_expert, confidence, routing_decision['reasoning']

class ReasoningEngine:
    """æ¨ç†å¼•æ“ï¼Œå¤„ç†å¤šè½®æ¨ç†å’Œæ€ç»´é“¾"""
    
    def __init__(self, router: IntelligentRouter):
        self.router = router
        self.conversation_history = []
        self.max_turns = 4
        
    def extract_thinking(self, text: str) -> str:
        """æå–<think>æ ‡ç­¾å†…å®¹"""
        pattern = re.compile(r"<think>(.*?)</think>", re.DOTALL)
        matches = pattern.findall(text)
        return matches[-1].strip() if matches else ""
    
    def extract_search(self, text: str) -> str:
        """æå–<search>æ ‡ç­¾å†…å®¹"""
        pattern = re.compile(r"<search>(.*?)</search>", re.DOTALL)
        matches = pattern.findall(text)
        return matches[-1].strip() if matches else ""
    
    def extract_answer(self, text: str) -> str:
        """æå–<answer>æ ‡ç­¾å†…å®¹"""
        pattern = re.compile(r"<answer>(.*?)</answer>", re.DOTALL)
        matches = pattern.findall(text)
        return matches[-1].strip() if matches else ""
    
    def should_continue_reasoning(self, current_info: str, turn: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æ¨ç†"""
        if turn >= self.max_turns:
            return False
            
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç­”æ¡ˆ
        if "<answer>" in current_info:
            return False
            
        # ç®€å•çš„å¯å‘å¼ï¼šå¦‚æœä¿¡æ¯è¿‡äºç®€å•ï¼Œç»§ç»­æ¨ç†
        if len(current_info) < 100:
            return True
            
        return random.random() < 0.6  # 60%çš„æ¦‚ç‡ç»§ç»­
    
    def generate_thinking(self, question: str, accumulated_info: str, turn: int) -> str:
        """ç”Ÿæˆæ€ç»´è¿‡ç¨‹"""
        thinking_patterns = [
            f"å¯¹äº'{question}'è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘éœ€è¦æ›´æ·±å…¥çš„ä¿¡æ¯æ¥ç»™å‡ºå…¨é¢çš„ç­”æ¡ˆã€‚",
            f"åŸºäºç›®å‰çš„ä¿¡æ¯ï¼Œæˆ‘éœ€è¦ä»ä¸åŒè§’åº¦æ¥éªŒè¯å’Œè¡¥å……ç­”æ¡ˆã€‚",
            f"è¿™ä¸ªé—®é¢˜æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘åº”è¯¥å’¨è¯¢ä¸€ä¸ªåœ¨è¿™ä¸ªé¢†åŸŸæ›´ä¸“ä¸šçš„æ¨¡å‹ã€‚",
            f"ä¸ºäº†ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆï¼Œæˆ‘éœ€è¦è·å–æ›´å¤šå…³äº'{question}'çš„ç»†èŠ‚ä¿¡æ¯ã€‚"
        ]
        
        if turn == 0:
            return f"å¯¹äºé—®é¢˜'{question}'ï¼Œæˆ‘éœ€è¦å…ˆç†è§£å…¶æ ¸å¿ƒè¦ç‚¹ï¼Œç„¶åç¡®å®šæ˜¯å¦éœ€è¦é¢å¤–çš„ä¸“ä¸šçŸ¥è¯†æ¥è¡¥å……ã€‚"
        elif turn == 1:
            return f"åŸºäºåˆæ­¥ä¿¡æ¯ï¼Œæˆ‘éœ€è¦è¿›ä¸€æ­¥éªŒè¯å’Œæ‰©å±•è¿™äº›è§‚ç‚¹ï¼Œä»¥ç¡®ä¿ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚"
        else:
            return random.choice(thinking_patterns)
    
    def generate_search_query(self, question: str, turn: int, accumulated_info: str) -> str:
        """ç”Ÿæˆæœç´¢æŸ¥è¯¢"""
        # æ ¹æ®è½®æ¬¡å’Œé—®é¢˜ç±»å‹ç”Ÿæˆä¸åŒçš„æŸ¥è¯¢
        if "å¼ºåŒ–å­¦ä¹ " in question or "reinforcement learning" in question.lower():
            queries = [
                "Qwen2.5-7B-Instruct:å¼ºåŒ–å­¦ä¹ åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„å…·ä½“åº”ç”¨å’ŒæŠ€æœ¬å®ç°",
                "LLaMA-3.1-70B-Instruct:å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒåŸç†å’Œç®—æ³•",
                "Mixtral-8x22B-Instruct:RLHFå’ŒPPOåœ¨å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„å®é™…æ•ˆæœ"
            ]
        elif "äººå·¥æ™ºèƒ½" in question or "AI" in question:
            queries = [
                "Qwen2.5-7B-Instruct:äººå·¥æ™ºèƒ½çš„æœ€æ–°å‘å±•è¶‹åŠ¿å’ŒæŠ€æœ¯çªç ´",
                "Gemma-2-27B-Instruct:äººå·¥æ™ºèƒ½åœ¨ä¸åŒè¡Œä¸šçš„åº”ç”¨å’Œå½±å“",
                "LLaMA-3.1-70B-Instruct:AIæŠ€æœ¯çš„æœªæ¥å‘å±•æ–¹å‘å’ŒæŒ‘æˆ˜"
            ]
        else:
            # é€šç”¨æŸ¥è¯¢ç”Ÿæˆ
            expert_names = [expert.name for expert in self.router.experts]
            selected_expert = random.choice(expert_names)
            queries = [f"{selected_expert}:{question}çš„è¯¦ç»†è§£é‡Šå’Œå…³é”®è¦ç‚¹"]
            
        return queries[min(turn, len(queries)-1)]

def complete_router_r1_demo(question: str):
    """å®Œæ•´çš„Router-R1æ™ºèƒ½è·¯ç”±æ¼”ç¤º"""
    print(f"ğŸš€ å¯åŠ¨Router-R1å®Œæ•´æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ")
    print(f"ğŸ“ é—®é¢˜: {question}")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    router = IntelligentRouter()
    reasoning_engine = ReasoningEngine(router)
    
    print(f"ğŸ§  åˆå§‹åŒ–ä¸“å®¶LLMæ± : {len(router.experts)}ä¸ªä¸“å®¶æ¨¡å‹")
    for expert in router.experts:
        print(f"  - {expert.name} (ä¸“é•¿: {', '.join(expert.expertise)}, æˆæœ¬: ${expert.cost_per_token:.4f}/token)")
    
    print("\n" + "-" * 80)
    print("ğŸ”„ å¼€å§‹å¤šè½®æ™ºèƒ½æ¨ç†...")
    
    # å‡†å¤‡åˆå§‹æç¤ºè¯
    question = question.strip()
    if question[-1] != '?':
        question += '?'
        
    current_prompt = prompt_pool.PROMPT_TEMPLATE_QWEN.format_map({"question": question})
    accumulated_info = ""
    total_cost = 0.0
    
    for turn in range(reasoning_engine.max_turns):
        print(f"\nğŸ”„ === ç¬¬ {turn + 1} è½®æ¨ç† ===")
        
        # 1. ç”Ÿæˆæ€ç»´è¿‡ç¨‹
        thinking = reasoning_engine.generate_thinking(question, accumulated_info, turn)
        print(f"ğŸ§ <think>\n{thinking}\n</think>")
        
        # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æ¨ç†
        if not reasoning_engine.should_continue_reasoning(accumulated_info, turn):
            print(f"\nğŸ ç»ˆæ­¢æ¡ä»¶æ»¡è¶³ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
            final_answer = f"åŸºäº{turn}è½®å¤šä¸“å®¶åä½œåˆ†æï¼Œå¯¹äº'{question}'çš„ç»¼åˆç­”æ¡ˆæ˜¯ï¼š\n\né€šè¿‡Router-R1ç³»ç»Ÿçš„æ™ºèƒ½è·¯ç”±ï¼Œæˆ‘ä»¬æˆåŠŸè°ƒç”¨äº†å¤šä¸ªä¸“ä¸šæ¨¡å‹æ¥æä¾›ä¸åŒè§’åº¦çš„åˆ†æã€‚è¿™ç§å¤šè½®äº¤äº’å’Œæ™ºèƒ½è·¯ç”±çš„æ–¹å¼ç¡®ä¿äº†ç­”æ¡ˆçš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚"
            print(f"ğŸ† <answer>\n{final_answer}\n</answer>")
            break
        
        # 3. ç”Ÿæˆæœç´¢æŸ¥è¯¢
        search_query = reasoning_engine.generate_search_query(question, turn, accumulated_info)
        print(f"\nğŸ” <search>{search_query}</search>")
        
        # 4. æ™ºèƒ½è·¯ç”±å†³ç­–
        selected_expert, confidence, reasoning = router.route_query(search_query.split(":", 1)[1] if ":" in search_query else search_query)
        print(f"\nğŸ¯ è·¯ç”±å†³ç­–:")
        print(f"  âœ… é€‰ä¸­æ¨¡å‹: {selected_expert.name}")
        print(f"  ğŸ“Š ç½®ä¿¡åº¦: {confidence:.2f}")
        print(f"  ğŸ’° æˆæœ¬: ${selected_expert.cost_per_token:.4f}/token")
        print(f"  ğŸ§ å†³ç­–ç†ç”±: {reasoning}")
        
        # 5. è·å–ä¸“å®¶å“åº”
        expert_response = selected_expert.generate_response(search_query, accumulated_info)
        current_cost = len(expert_response) * selected_expert.cost_per_token
        total_cost += current_cost
        
        print(f"\nğŸ“¥ <information>\n{expert_response}\n</information>")
        print(f"ğŸ’¸ æœ¬è½®æˆæœ¬: ${current_cost:.6f}")
        
        # 6. æ›´æ–°ä¸Šä¸‹æ–‡
        accumulated_info += f"\n\nç¬¬{turn+1}è½®ä¿¡æ¯ - æ¥è‡ª{selected_expert.name}:\n{expert_response}"
        current_prompt += f"\n\n<think>{thinking}</think>\n<search>{search_query}</search>\n<information>{expert_response}</information>"
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ç³»ç»Ÿç»Ÿè®¡:")
    print(f"  ğŸ”„ æ€»è½®æ¬¡: {turn + 1}")
    print(f"  ğŸ’° æ€»æˆæœ¬: ${total_cost:.6f}")
    print(f"  ğŸ¯ è·¯ç”±å†å²: {len(router.routing_history)}æ¬¡å†³ç­–")
    
    print("\nğŸ“ è·¯ç”±å†³ç­–è¯¦æƒ…:")
    for i, decision in enumerate(router.routing_history):
        print(f"  {i+1}. {decision['selected_expert']} (ç½®ä¿¡åº¦: {decision['confidence']:.2f}, ä»»åŠ¡: {decision['query_type']})")
    
    return {
        'total_turns': turn + 1,
        'total_cost': total_cost,
        'routing_decisions': router.routing_history,
        'final_prompt': current_prompt
    }

def get_query(text):
    """å…¼å®¹æ€§å‡½æ•° - ä»ç”Ÿæˆçš„æ–‡æœ¬ä¸­æå–æŸ¥è¯¢å†…å®¹"""
    pattern = re.compile(r"<search>(.*?)</search>", re.DOTALL)
    matches = pattern.findall(text)
    return matches[-1] if matches else None

def main():
    parser = argparse.ArgumentParser(description='Router-R1 å®Œæ•´æ™ºèƒ½è·¯ç”±æ¼”ç¤º')
    parser.add_argument('--question', type=str, 
                       default="ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨å’Œæœªæ¥å‘å±•è¶‹åŠ¿", 
                       help='è¦å›ç­”çš„é—®é¢˜')
    parser.add_argument('--simple', action='store_true',
                       help='æ˜¯å¦ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼ˆå…¼å®¹æ€§ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸŒŸ æ¬¢è¿ä½¿ç”¨ Router-R1 å®Œæ•´æ™ºèƒ½è·¯ç”±æ¼”ç¤ºç³»ç»Ÿï¼")
    print("ğŸ¯ å±•ç¤ºçœŸæ­£çš„å¤šLLMåä½œã€æ™ºèƒ½è·¯ç”±å’Œå¤šè½®æ¨ç†")
    print("ğŸ”¬ è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„AIç³»ç»Ÿæ¼”ç¤ºï¼ŒåŒ…å«ï¼š")
    print("   - æ™ºèƒ½è·¯ç”±å†³ç­–ç®—æ³•")
    print("   - å¤šä¸“å®¶LLMåä½œ")
    print("   - è‡ªé€‚åº”æ¨ç†æµç¨‹")
    print("   - æˆæœ¬æ•ˆç›Šä¼˜åŒ–")
    
    if args.simple:
        print("\nâš ï¸  è¿è¡Œç®€åŒ–å…¼å®¹æ¨¡å¼...")
        # ç®€åŒ–ç‰ˆæœ¬çš„é€»è¾‘ä¿æŒå‘åå…¼å®¹
        simple_demo_fallback(args.question)
    else:
        # è¿è¡Œå®Œæ•´ç‰ˆæœ¬
        try:
            result = complete_router_r1_demo(args.question)
            
            print("\nğŸŠ æ¼”ç¤ºæ€»ç»“:")
            print(f"âœ… æˆåŠŸå±•ç¤ºäº†Router-R1çš„æ ¸å¿ƒèƒ½åŠ›:")
            print(f"   - æ™ºèƒ½è·¯ç”±: {len(result['routing_decisions'])}æ¬¡ç²¾å‡†å†³ç­–")
            print(f"   - å¤šè½®æ¨ç†: {result['total_turns']}è½®åä½œä¼˜åŒ–")
            print(f"   - æˆæœ¬æ§åˆ¶: ${result['total_cost']:.6f}æ€»æˆæœ¬")
            print(f"   - ä¸“å®¶åä½œ: å¤šä¸ªä¸“ä¸šæ¨¡å‹å‚ä¸")
            
        except Exception as e:
            print(f"\nâš ï¸  å®Œæ•´æ¨¡å¼å‡ºç°é—®é¢˜: {e}")
            print("ğŸ”„ åˆ‡æ¢åˆ°ç®€åŒ–å…¼å®¹æ¨¡å¼...")
            simple_demo_fallback(args.question)

def simple_demo_fallback(question: str):
    """ç®€åŒ–ç‰ˆæœ¬çš„æ¼”ç¤ºï¼Œç”¨äºå…¼å®¹æ€§"""
    print(f"\nğŸ“ é—®é¢˜: {question}")
    print("\nğŸ­ è¿è¡ŒåŸºç¡€æ¼”ç¤ºæ¨¡å¼...")
    
    # åŸºç¡€çš„å¤šè½®å¯¹è¯å±•ç¤º
    print("\nğŸ”„ ç¬¬1è½®: åˆ†æé—®é¢˜")
    print("ğŸ§  <think>è¿™ä¸ªé—®é¢˜éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œæˆ‘éœ€è¦è·¯ç”±åˆ°åˆé€‚çš„ä¸“å®¶æ¨¡å‹</think>")
    print("ğŸ” <search>Qwen2.5-7B-Instruct:å¼ºåŒ–å­¦ä¹ åœ¨è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„å…·ä½“åº”ç”¨</search>")
    print("ğŸ“¥ <information>å¼ºåŒ–å­¦ä¹ ä¸»è¦é€šè¿‡RLHFå’ŒPPOç®—æ³•ä¼˜åŒ–è¯­è¨€æ¨¡å‹...</information>")
    
    print("\nğŸ”„ ç¬¬2è½®: æ·±å…¥åˆ†æ")
    print("ğŸ§  <think>éœ€è¦æ›´æŠ€æœ¯æ€§çš„è§£é‡Šï¼Œé€‰æ‹©æ›´å¤§çš„æ¨¡å‹</think>")
    print("ğŸ” <search>LLaMA-3.1-70B-Instruct:RLHFå’ŒPPOç®—æ³•çš„æŠ€æœ¯ç»†èŠ‚</search>")
    print("ğŸ“¥ <information>RLHFåŒ…æ‹¬å¥–åŠ±æ¨¡å‹è®­ç»ƒå’Œç­–ç•¥ä¼˜åŒ–ä¸¤ä¸ªé˜¶æ®µ...</information>")
    
    print("\nğŸ”„ ç¬¬3è½®: ç»¼åˆæ€»ç»“")
    print("ğŸ§  <think>ç°åœ¨å¯ä»¥ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆäº†</think>")
    print("ğŸ¯ <answer>å¼ºåŒ–å­¦ä¹ åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨åŒ…æ‹¬RLHFè®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒç­‰ï¼Œæœªæ¥å°†å‘æ›´é«˜æ•ˆçš„ç®—æ³•å‘å±•</answer>")
    
    print("\nâœ… åŸºç¡€æ¼”ç¤ºå®Œæˆï¼å±•ç¤ºäº†Router-R1çš„æ ¸å¿ƒæµç¨‹æ¦‚å¿µã€‚")

if __name__ == "__main__":
    main()